## How to generate text: using different decoding methods for language generation with Transformers
Greedy search, Beam search, Top-K sampling and Top-p sampling </br>

https://huggingface.co/blog/how-to-generate

## Leveraging Pre-trained Checkpoints for Encoder-Decoder Models.ipynb

https://colab.research.google.com/github/patrickvonplaten/notebooks/blob/master/Leveraging_Pre_trained_Checkpoints_for_Encoder_Decoder_Models.ipynb#scrollTo=yfhyBz-ZsVJe

